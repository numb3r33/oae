{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import re\n",
    "import IPython, graphviz\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from oae.core import *\n",
    "\n",
    "SEED = 41\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['ATMSKLEARN', 'Instance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation\n",
    "\n",
    "> How to represent a trained Random Forest ( scikit-learn ) model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_tree(t, df, size=10, ratio=0.6, precision=0):\n",
    "    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n",
    "                      special_characters=True, rotate=True, precision=precision)\n",
    "    IPython.display.display(graphviz.Source(re.sub('Tree {',\n",
    "       f'Tree {{ size={size}; ratio={ratio}', s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xte, ytr, yte = get_example_dataset(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, n_jobs=-1, random_state=41)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=5, random_state=SEED, n_jobs=-1)\n",
    "clf.fit(Xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "df_trn = pd.DataFrame(Xtr, columns=[f'f_{i}' for i in range(5)])\n",
    "#draw_tree(clf.estimators_[0], df_trn, precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ATMSKLEARN:\n",
    "    def __init__(self, trained_model, X):\n",
    "        self.trained_model = trained_model\n",
    "        self.X = X\n",
    "        \n",
    "        self.check_tree_with_no_leaves()\n",
    "        \n",
    "    def check_tree_with_no_leaves(self):\n",
    "        for tidx, t in enumerate(self.get_trees()):\n",
    "            if len(t.tree_.feature) < 0: raise ValueError(f'Tree: {tidx} has no leaves.')\n",
    "        \n",
    "    def get_trees(self):\n",
    "        return self.trained_model.estimators_\n",
    "    \n",
    "    @property\n",
    "    def num_trees(self):\n",
    "        return len(self.get_trees())\n",
    "    \n",
    "    def calculate_tree_weights(self):\n",
    "        T = self.num_trees\n",
    "        return np.ones(shape=(T, )) / T\n",
    "    \n",
    "    def get_leaves(self, tree):\n",
    "        return np.where(tree.feature < 0)[0]\n",
    "    \n",
    "    def get_leaves_value(self, tree, leaves):\n",
    "        return np.array([tree.value[l] for l in leaves])\n",
    "    \n",
    "    def get_node_threshold(self, tree, fidx):\n",
    "        idx = np.where(tree.feature == fidx)[0]\n",
    "        return list(tree.threshold[idx]) if len(idx) > 0 else []\n",
    "    \n",
    "    def make_partitions_num(self, splits, INF=1e8):\n",
    "        splits = np.insert(splits, 0, -INF)\n",
    "        splits = np.insert(splits, len(splits), INF)\n",
    "        \n",
    "        partitions = []\n",
    "        for i in range(len(splits) - 1):\n",
    "            partitions.append([splits[i], splits[i+1]])\n",
    "\n",
    "        return partitions\n",
    "    \n",
    "    def make_partitions_cat(self, splits):\n",
    "        max_val = splits[-1] + 1\n",
    "        splits  = np.insert(splits, len(splits), max_val)\n",
    "        \n",
    "        partitions = []\n",
    "        for i in range(len(splits) - 1):\n",
    "            partitions.append([splits[i], splits[i+1]])\n",
    "        return partitions\n",
    "    \n",
    "    def h_k(self, tree, combine, class_):\n",
    "        leaves = self.get_leaves(tree)\n",
    "        leaves_value = self.get_leaves_value(tree, leaves)\n",
    "        return combine(leaves_value, class_)\n",
    "    \n",
    "    def h_t_k(self, combine, class_=None):\n",
    "        return [self.h_k(tree.tree_, combine, class_) for tree in self.get_trees()]\n",
    "    \n",
    "    def phi_k(self, tree, x):\n",
    "        leaves = self.get_leaves(tree)\n",
    "        return [tree.decision_path(x.astype(np.float32)).toarray().ravel()[leaf] for leaf in leaves]\n",
    "    \n",
    "    def phi_t_k(self, x):\n",
    "        return [self.phi_k(tree.tree_, x) for tree in self.get_trees()]\n",
    "    \n",
    "    def feature_partitions_cat(self, fidx):\n",
    "        splits  = np.sort(np.unique(self.X[:, fidx]))\n",
    "        return self.make_partitions_cat(splits)\n",
    "    \n",
    "    def feature_partitions_num(self, fidx):\n",
    "        splits = np.hstack([self.get_node_threshold(tree.tree_, fidx) for tree in self.get_trees()])\n",
    "        splits = np.sort(np.unique(splits))\n",
    "        return self.make_partitions_num(splits)\n",
    "    \n",
    "    def v_j(self, fidx, ftype):\n",
    "        if ftype == 'categorical': return self.feature_partitions_cat(fidx)\n",
    "        else: return self.feature_partitions_num(fidx)\n",
    "        \n",
    "    def v_i_j(self, feature):\n",
    "        fdtypes = feature.dtypes\n",
    "        feat    = feature.content\n",
    "        return [self.v_j(i, fdtypes[i]) for i in range(len(fdtypes))]\n",
    "    \n",
    "    def v_j_mask(self, partition, fval, ftype):\n",
    "        mask = []\n",
    "        \n",
    "        for s in partition:\n",
    "            if ftype == 'numerical':\n",
    "                if (fval > s[0]) and (fval <= s[1]):\n",
    "                    mask.append(1)\n",
    "                else:\n",
    "                    mask.append(0)\n",
    "            else:\n",
    "                if (fval >= s[0]) and (fval < s[1]):\n",
    "                    mask.append(1)\n",
    "                else:\n",
    "                    mask.append(0)\n",
    "                    \n",
    "        return mask\n",
    "    \n",
    "    def v_i_j_mask(self, partitions, feature):\n",
    "        return [self.v_j_mask(partitions[i], feature.content[i], feature.types[i]) for i in range(len(partitions))]\n",
    "    \n",
    "    def mask_v_j(self, mask, partition):\n",
    "        return [partition[midx] for midx, m in enumerate(mask) if m]\n",
    "    \n",
    "    def masks_v_i_j(self, masks, partitions):\n",
    "        return [self.mask_v_j(masks[i], partitions[i]) for i in range(len(partitions))]\n",
    "    \n",
    "    \n",
    "    def suggest_changes(self, sol_mask, feature):\n",
    "        partitions = self.v_i_j(feature)\n",
    "        orig_mask  = self.v_i_j_mask(partitions, feature)\n",
    "        \n",
    "        changes = []\n",
    "        for i in range(len(sol_mask)):\n",
    "            if sol_mask[i] == orig_mask[i]:\n",
    "                changes.append(f'no change, current value: {feature.content[i]}')\n",
    "            else:\n",
    "                sol_mask_one_idx  = np.where(np.array(sol_mask[i]) == 1)[0][0]\n",
    "                changes.append(f'current value: {feature.content[i]}, proposed change: {partitions[i][sol_mask_one_idx]}')\n",
    "        \n",
    "        return changes\n",
    "    \n",
    "    def transform(self, sol_mask, feature):\n",
    "        partitions = self.v_i_j(feature)\n",
    "        orig_mask  = self.v_i_j_mask(partitions, feature)\n",
    "        \n",
    "        fnames = feature.fnames\n",
    "        dtypes = feature.types\n",
    "        \n",
    "        transformed_feature = []\n",
    "        \n",
    "        for i in range(len(sol_mask)):\n",
    "            if sol_mask[i] == orig_mask[i]:\n",
    "                transformed_feature.append(feature.content[i])\n",
    "            else:\n",
    "                sol_mask_one_idx  = np.where(np.array(sol_mask[i]) == 1)[0][0]\n",
    "                if dtypes[i] == 'numerical':\n",
    "                    if i <= len(dtypes) - 1:\n",
    "                        transformed_feature.append(partitions[i][sol_mask_one_idx][1])\n",
    "                    else:\n",
    "                        diff = partitions[i][sol_mask_one_idx][1] - partitions[i][sol_mask_one_idx][0]\n",
    "                        scaled_diff = diff * 0.1\n",
    "                        transformed_feature.append(np.random.uniform(partitions[i][sol_mask_one_idx][0] + scaled_diff,\n",
    "                                                                 partitions[i][sol_mask_one_idx][1]\n",
    "                                                                ))\n",
    "                        \n",
    "                else:\n",
    "                    transformed_feature.append(partitions[i][sol_mask_one_idx][0])\n",
    "                    \n",
    "        return pd.DataFrame(np.array(transformed_feature).reshape(1, -1), columns=fnames)\n",
    "        \n",
    "    def find_ancestors(self, tree, node, leaf_node, p):\n",
    "        if node == leaf_node: return [True, p]\n",
    "        if tree.feature[node] < 0: \n",
    "            p.pop()\n",
    "            return [False, p]\n",
    "\n",
    "        in_left_branch, p = (self.find_ancestors(tree, tree.children_left[node], leaf_node, p + [(node, 'left')]))\n",
    "        if in_left_branch: return [True, p]\n",
    "\n",
    "        in_right_branch, p = (self.find_ancestors(tree, tree.children_right[node], leaf_node, p + [(node, 'right')]))\n",
    "        if in_right_branch: return [True, p]\n",
    "\n",
    "        p.pop()\n",
    "        return [False, p]\n",
    "    \n",
    "    def pi_k(self, tree):\n",
    "        leaves = self.get_leaves(tree)\n",
    "        root_index = 0\n",
    "        return {kidx:self.find_ancestors(tree, node=root_index, leaf_node=k, p=[])[1] for kidx, k in enumerate(leaves)}\n",
    "        \n",
    "    def pi_t_k(self):\n",
    "        trees = self.get_trees()\n",
    "        return [self.pi_k(tree.tree_) for tree in trees]\n",
    "    \n",
    "    def predicate_mask(self, tree, fname, fidx, branch, v_i_j, dtype):\n",
    "        threshold = tree.threshold[fidx]\n",
    "        filter_predicates = []\n",
    "        \n",
    "        if branch == 'left':\n",
    "            for p in v_i_j[fname]:\n",
    "                if dtype == 'numerical':\n",
    "                    if p[len(p) - 1] <= threshold:\n",
    "                        filter_predicates.append(1)\n",
    "                    else:\n",
    "                        filter_predicates.append(0)\n",
    "                else:\n",
    "                    if p[len(p) - 1] < threshold:\n",
    "                        filter_predicates.append(1)\n",
    "                    else:\n",
    "                        if (p[0] <= threshold):\n",
    "                            filter_predicates.append(1)\n",
    "                        else:\n",
    "                            filter_predicates.append(0)\n",
    "        else:\n",
    "            for p in v_i_j[fname]:\n",
    "                if dtype == 'numerical':\n",
    "                    if p[0] >= threshold:\n",
    "                        filter_predicates.append(1)\n",
    "                    else:\n",
    "                        filter_predicates.append(0)\n",
    "                else:\n",
    "                    if p[0] > threshold:\n",
    "                        filter_predicates.append(1)\n",
    "                    else:\n",
    "                        filter_predicates.append(0)\n",
    "            \n",
    "        return filter_predicates\n",
    "\n",
    "    def predicates_mask(self, tree, ancestor, v_i_j, dtypes):\n",
    "        p, p_branch = ancestor\n",
    "        fname = tree.feature[p]\n",
    "        dtype = dtypes[fname]\n",
    "        return self.predicate_mask(tree, fname, p, p_branch, v_i_j, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def combine(leaves_value, class_):\n",
    "    if class_ is None: class_ = 1\n",
    "    return [(c.ravel() / c.ravel().sum())[class_] for c in leaves_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atm = ATMSKLEARN(clf, np.vstack((Xtr, Xte)))\n",
    "\n",
    "assert atm.num_trees == 5\n",
    "assert all(atm.calculate_tree_weights() == np.array([1/5] * 5))\n",
    "\n",
    "def combine(leaves_value, class_):\n",
    "    if class_ is None: class_ = 1\n",
    "    return [(c.ravel() / c.ravel().sum())[class_] for c in leaves_value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each leaf node $k = 1,. . ., m_t$, we use a binary variable $\\phi_{t,k}$ âˆˆ {0, 1} to denote whether a given instance x reaches it. Due to the property of the tree structure, each instance reaches exactly one leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sum_{k=1}^{m_t} \\phi_{t,k} = 1  $$for t = 1,...,T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a particular instance `Xte[4]` the following matrix represents in which leaf node would this instance reach. e.g:\n",
    "for tree-0 this instance would reach 0th leaf, for tree-1 this instance would also reach 0th leaf and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atm.phi_t_k(Xte[4:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test is to check whether an instance reaches exactly one leaf one in all trees or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([sum(r) == 1 for r in atm.phi_t_k(Xte[4:5])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, $f_{t}(x)$ can be expressed as:\n",
    "$f_{t}(x) = \\sum_{k=1}^{m_t} h_{t,k}\\phi_{t,k}$, where $h_{t_k} \\in R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of classification, we look at the class distribution of leaves and report average as $h_{t,k}$ for k-th leaf node of t-th tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_t_k   = atm.h_t_k(combine)\n",
    "phi_t_k = atm.phi_t_k(Xte[4:5]) \n",
    "w_t     = atm.calculate_tree_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2, 0.8]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(Xte[4:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following test is to verify that $f_{t}(x) = \\frac{1}{w_{t}} \\sum_{k=1}^{m_t} h_{t,k}\\phi_{t,k}$, where $h_{t_k} \\in R$ is equal to `clf.predict_proba(x)[1]` or not, assuming `1` is the class of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 1e-6\n",
    "assert np.abs(np.sum([h_t_k[i][j] * phi_t_k[i][j] * w_t[i] for i in range(len(h_t_k)) for j in range(len(h_t_k[i]))])\\\n",
    "              - 0.8) < tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Instance:\n",
    "    def __init__(self, x, dtypes):\n",
    "        if len(dtypes) == 0: raise ValueError('Data type list cannot be empty')\n",
    "        \n",
    "        if isinstance(x, pd.Series): self.content = x.values\n",
    "        else: self.content = np.array(x)\n",
    "        \n",
    "        if isinstance(x, pd.Series): self.feat_names = x.index.tolist()\n",
    "        else: self.feat_names = [f'f_{i}' for i in range(len(x))]\n",
    "        \n",
    "        self.types = dtypes\n",
    "    \n",
    "    @property\n",
    "    def value(self): return self.content\n",
    "    @property\n",
    "    def dtypes(self): return self.types\n",
    "    @property\n",
    "    def fnames(self): return self.feat_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an additive tree model, each feature $x_i, i = 1,..., D$, is split into a\n",
    "number of partitions.\n",
    "- If $x_i$ is categorical with n categories, then xi naturally has n partitions.\n",
    "- If $x_i$ is numerical, we assume each tree node branches in the form of $x_i \\geq b$ where $b \\in R$ is a splitting point.\n",
    "\n",
    "If there are n splitting points for $x_i$ in all the trees in the additive tree model, the feature $x_i$ is naturally split into n + 1 partitions. In the following, let $n_i$ be the number of partitions for feature $x_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature value variables. Given an instance x, we use a binary variable $v_{i,j} \\in \\{0, 1\\}$ to denote whether $x_i$ is in the jth partition of dimension i. $v_{i,j} = 1$ if and only if $x_i$ is in the jth partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since an instance could only reside in exactly one partition for each feature, we know that $v_{i,j}$ should satisfy\n",
    "\n",
    "$$\\sum_{j=1}^{n_i} v_{i,j} = 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atm = ATMSKLEARN(clf, np.vstack((Xtr, Xte)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f_0', 'f_1', 'f_2', 'f_3', 'f_4']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance = Instance(Xte[4], ['numerical'] * 5)\n",
    "instance.fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numerical', 'numerical', 'numerical', 'numerical', 'numerical']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`atm.v_i_j(instance)` lists down all the partitions based on feature type for a particular instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[-100000000.0, -2.0248294472694397],\n",
       "  [-2.0248294472694397, -1.2423902750015259],\n",
       "  [-1.2423902750015259, -1.0648272037506104],\n",
       "  [-1.0648272037506104, -0.42396698892116547],\n",
       "  [-0.42396698892116547, -0.10306572914123535],\n",
       "  [-0.10306572914123535, 0.6439935863018036],\n",
       "  [0.6439935863018036, 0.6447310447692871],\n",
       "  [0.6447310447692871, 0.836201936006546],\n",
       "  [0.836201936006546, 0.8496142029762268],\n",
       "  [0.8496142029762268, 0.914455235004425],\n",
       "  [0.914455235004425, 1.096608817577362],\n",
       "  [1.096608817577362, 1.1486619710922241],\n",
       "  [1.1486619710922241, 1.5790348649024963],\n",
       "  [1.5790348649024963, 100000000.0]],\n",
       " [[-100000000.0, -1.470717191696167],\n",
       "  [-1.470717191696167, -1.1500263214111328],\n",
       "  [-1.1500263214111328, -0.5423658043146133],\n",
       "  [-0.5423658043146133, -0.531291589140892],\n",
       "  [-0.531291589140892, -0.12118824571371078],\n",
       "  [-0.12118824571371078, 0.1686990186572075],\n",
       "  [0.1686990186572075, 0.35822106897830963],\n",
       "  [0.35822106897830963, 0.41557787358760834],\n",
       "  [0.41557787358760834, 2.3792918920516968],\n",
       "  [2.3792918920516968, 100000000.0]],\n",
       " [[-100000000.0, -1.4785081148147583],\n",
       "  [-1.4785081148147583, -0.8463370203971863],\n",
       "  [-0.8463370203971863, -0.7427763640880585],\n",
       "  [-0.7427763640880585, -0.6585032045841217],\n",
       "  [-0.6585032045841217, -0.1557881347835064],\n",
       "  [-0.1557881347835064, -0.14745968580245972],\n",
       "  [-0.14745968580245972, 0.10728693753480911],\n",
       "  [0.10728693753480911, 0.2427385449409485],\n",
       "  [0.2427385449409485, 0.30658136308193207],\n",
       "  [0.30658136308193207, 0.3585205078125],\n",
       "  [0.3585205078125, 0.38348717987537384],\n",
       "  [0.38348717987537384, 0.4289112240076065],\n",
       "  [0.4289112240076065, 0.4685207009315491],\n",
       "  [0.4685207009315491, 100000000.0]],\n",
       " [[-100000000.0, -0.24541949480772018],\n",
       "  [-0.24541949480772018, -0.16905810683965683],\n",
       "  [-0.16905810683965683, -0.1664411947131157],\n",
       "  [-0.1664411947131157, -0.14978579431772232],\n",
       "  [-0.14978579431772232, -0.14464405924081802],\n",
       "  [-0.14464405924081802, -0.033745707711204886],\n",
       "  [-0.033745707711204886, -0.002453504828736186],\n",
       "  [-0.002453504828736186, 0.11794959381222725],\n",
       "  [0.11794959381222725, 0.2094322368502617],\n",
       "  [0.2094322368502617, 0.25495275668799877],\n",
       "  [0.25495275668799877, 100000000.0]],\n",
       " [[-100000000.0, -1.136821210384369],\n",
       "  [-1.136821210384369, -1.0038151741027832],\n",
       "  [-1.0038151741027832, -0.8827621340751648],\n",
       "  [-0.8827621340751648, -0.38978028297424316],\n",
       "  [-0.38978028297424316, -0.31629133224487305],\n",
       "  [-0.31629133224487305, 0.07762494683265686],\n",
       "  [0.07762494683265686, 0.2304462417960167],\n",
       "  [0.2304462417960167, 0.3767264783382416],\n",
       "  [0.3767264783382416, 0.4243736043572426],\n",
       "  [0.4243736043572426, 0.4500375986099243],\n",
       "  [0.4500375986099243, 0.5001247227191925],\n",
       "  [0.5001247227191925, 0.6438964009284973],\n",
       "  [0.6438964009284973, 0.6848085820674896],\n",
       "  [0.6848085820674896, 0.836023598909378],\n",
       "  [0.836023598909378, 0.9093806743621826],\n",
       "  [0.9093806743621826, 100000000.0]]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atm.v_i_j(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atm = ATMSKLEARN(clf, np.vstack((Xtr, Xte)))\n",
    "\n",
    "partitions = atm.v_i_j(instance)\n",
    "v_i_j_mask = atm.v_i_j_mask(partitions, instance)\n",
    "\n",
    "assert all([np.sum(x) == 1 for x in v_i_j_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a leaf node $k$ in tree $t$, suppose $\\pi_{t,k}$ is the set of all its ancestor nodes in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atm = ATMSKLEARN(clf, np.vstack((Xtr, Xte)))\n",
    "\n",
    "pi_t_k  = atm.pi_t_k()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`atm.predicates_mask(tree, pi_t_k[t][k][p], partitions)` represents $s_{k,p}$, where\n",
    "\n",
    "For any node $p \\in \\pi_{t,k}$, suppose $p$ branches on feature $i$, we define $S_{k,p}$ to be the set containing all predicates $v_{i,j}$ satisfying that $v_{i,j}$ = 1 leads to the branch towards leaf node $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atm = ATMSKLEARN(clf, np.vstack((Xtr, Xte)))\n",
    "\n",
    "h_t_k   = atm.h_t_k(combine)\n",
    "phi_t_k = atm.phi_t_k(Xte[4:5]) \n",
    "w_t     = atm.calculate_tree_weights()\n",
    "\n",
    "\n",
    "instance   = Instance(Xte[4], ['numerical'] * 5)\n",
    "partitions = atm.v_i_j(instance)\n",
    "v_i_j_mask = atm.v_i_j_mask(partitions, instance)\n",
    "\n",
    "pi_t_k  = atm.pi_t_k()\n",
    "\n",
    "atm.predicates_mask(clf.estimators_[0].tree_, pi_t_k[0][0][1], partitions, instance.types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t_k_p = [[{a[0]:atm.predicates_mask(t.tree_, a, partitions, instance.types) for a in pi_t_k[tidx][kidx]}\\\n",
    "           for kidx, k in enumerate(atm.get_leaves(t.tree_))] \\\n",
    "           for tidx, t in enumerate(clf.estimators_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making use of the tree structure, we have the following properties:\n",
    "- If $\\phi_{t,k} = 1$, meaning that the instance x lies in the leaf node k in tree t, then there is always one of the predicates $v_{i,j}$ in $S_{k,p}$ being 1 for any node $p \\in \\pi_{t,k}$.\n",
    "- If $\\phi_{t,k} = 0$, then there exists at least one node p such that all the predicates in $S_{k,p}$ are 0.\n",
    "\n",
    "Combining above two, we get\n",
    "\n",
    "$$\\phi_{t, k} \\leq \\frac {1}{\\mid {\\pi_{t,k}}\\mid} \\sum_{p \\in \\pi_{t,k}}\\sum_{v \\in s_{k,p}} v, \\forall t,k$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = atm.get_trees()\n",
    "\n",
    "for i in range(len(trees)):\n",
    "    for j in range(len(atm.get_leaves(trees[i].tree_))):\n",
    "        res = 0\n",
    "        nancestors = len(pi_t_k[i][j])\n",
    "        for k, predicate in s_t_k_p[i][j].items():\n",
    "            res += np.sum(np.array(predicate) * np.array(v_i_j_mask[trees[i].tree_.feature[k]]))\n",
    "        \n",
    "        if phi_t_k[i][j] > (res / nancestors):\n",
    "            raise AssertionError('Decision Logic constraint violated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oae_env",
   "language": "python",
   "name": "oae_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
